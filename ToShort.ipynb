{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26d65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install pyppeteer\n",
    "\n",
    "!pip install youtube-transcript-api \n",
    "!pip install -U scikit-learn scipy matplotlib\n",
    "!pip install sklearn \n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_lg \n",
    "!pip install nltk\n",
    "\n",
    "\n",
    "!pip install soundfile\n",
    "!pip install transformers[torch]\n",
    "!pip install torchaudio --user \n",
    "!pip install librosa --user \n",
    "!pip install PySoundFile --user\n",
    "!pip install git+https://github.com/huggingface/datasets.git\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "!pip install gensim\n",
    "\n",
    "!pip install audb\n",
    "!pip install opensmile\n",
    "\n",
    "!pip install speechbrain --user\n",
    "!pip install --upgrade pip\n",
    "!pip install speechbrain --user\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests, json\n",
    "import subprocess, os, argparse, datetime, re, sys,math  ,time\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans  #For applying KMeans\n",
    "from sklearn.metrics import silhouette_score , calinski_harabasz_score , davies_bouldin_score  ,pairwise_distances_argmin\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import torch\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "\n",
    "from transformers import AutoConfig, Wav2Vec2FeatureExtractor\n",
    "\n",
    "\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import (\n",
    "    Wav2Vec2PreTrainedModel,\n",
    "    Wav2Vec2Model\n",
    ")\n",
    "\n",
    "from transformers.file_utils import ModelOutput\n",
    "\n",
    "from speechbrain.pretrained.interfaces import foreign_class\n",
    "\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "import audb\n",
    "import audiofile\n",
    "import opensmile\n",
    "\n",
    "from scipy.io import wavfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bda6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getUrlsFromIds(lst_links_str,isId = True):\n",
    "    lst_links_str_cpy = lst_links_str.copy()\n",
    "    if (isId) :\n",
    "        for i in range(len(lst_links_str_cpy)) :\n",
    "            lst_links_str_cpy[i] = \"https://www.youtube.com/watch?v=\"+lst_links_str_cpy[i] if not( \"https://www.youtube.com/watch?v=\" in lst_links_str_cpy[i]) else lst_links_str_cpy[i]\n",
    "    return lst_links_str_cpy\n",
    "\n",
    "\n",
    "def getContentFromURL(url):\n",
    "    return requests.get(url).text\n",
    "\n",
    "def getvideoInfo(  videoId):\n",
    "    url = f'https://yt.lemnoslife.com/videos?part=mostReplayed&id={videoId}'\n",
    "    content = getContentFromURL(url)\n",
    "    data = json.loads(content)\n",
    "    return data\n",
    "\n",
    "def getvideosInfos(videoIds , isId = True ):\n",
    "    return [getvideoInfo(videoId) for videoId in videoIds]\n",
    "    \n",
    "\n",
    "def getHeatMarkersDataVideo(data):\n",
    "    return data[\"items\"][0]['mostReplayed']['heatMarkers'] if bool(data[\"items\"][0] ) else []\n",
    "\n",
    "def getHeatMarkersDatasVideos(data):\n",
    "    return [getHeatMarkersDataVideo(videoData) for videoData in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getLenVideo(data_wh):\n",
    "\n",
    "    d=data_wh[-1]['heatMarkerRenderer']\n",
    "    len=d['timeRangeStartMillis' ] +d['markerDurationMillis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42470fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterMoreThanMean(data, fields ,x_field,y_field,z_field, mean):\n",
    "    res=[]\n",
    "    m=0\n",
    "    l = len(data)\n",
    "    for i in range(l) :\n",
    "        d1=data[i]\n",
    "        for field in fields : \n",
    "            d1=d1[field]\n",
    "        m+=d1[z_field]\n",
    "        if d1[y_field] > mean :\n",
    "            res.append([d1[x_field],d1[y_field]])\n",
    "            \n",
    "    \n",
    "    return res , m/l\n",
    "\n",
    "def filterData(data,fields=['heatMarkerRenderer'], x_field = 'timeRangeStartMillis' , cmp_field = 'heatMarkerIntensityScoreNormalized' , z_field = 'markerDurationMillis' ,seuil=0.5):\n",
    "    return filterMoreThanMean(data[2:], fields, x_field,cmp_field,z_field , seuil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeafcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_cluster (X , k_min , k_max , seed_random ):\n",
    "    if(not(bool(X))):\n",
    "        return [],0,[]\n",
    "    \n",
    "    \n",
    "    fitted_kmeans = {}\n",
    "    labels_kmeans = {}\n",
    "    df_scores = []\n",
    "    centroids= {}\n",
    "\n",
    "    l_x = len(X)\n",
    "    k_max = k_max if l_x > k_max else l_x \n",
    "\n",
    "    for n_clusters in range(k_min,k_max):\n",
    "        \n",
    "        #Perform clustering.\n",
    "        kmeans = KMeans(n_clusters=n_clusters,\n",
    "                        random_state=seed_random,\n",
    "                        )\n",
    "        labels_clusters = kmeans.fit_predict(X)\n",
    "        \n",
    "        #Insert fitted model and calculated cluster labels in dictionaries,\n",
    "        #for further reference.\n",
    "        fitted_kmeans[n_clusters] = kmeans\n",
    "        labels_kmeans[n_clusters] = labels_clusters\n",
    "        centroids[n_clusters]  = kmeans.cluster_centers_ \n",
    "    \n",
    "        #Calculate various scores, and save them for further reference.\n",
    "        silhouette = silhouette_score(X, labels_clusters)\n",
    "        ch = calinski_harabasz_score(X, labels_clusters)\n",
    "        db = davies_bouldin_score(X, labels_clusters)\n",
    "        tmp_scores = {\"n_clusters\": n_clusters,\n",
    "                      \"silhouette_score\": silhouette,\n",
    "                      \"calinski_harabasz_score\": ch,\n",
    "                      \"davies_bouldin_score\": -db,\n",
    "                      }\n",
    "        df_scores.append(tmp_scores)\n",
    "\n",
    "    #Create a DataFrame of clustering scores, using `n_clusters` as index, for easier plotting.\n",
    "    \n",
    "    df_scores = pd.DataFrame(df_scores)\n",
    "    df_scores.set_index(\"n_clusters\", inplace=True)\n",
    "\n",
    "  \n",
    "\n",
    "    df_ = df_scores.sort_values(by=['silhouette_score','calinski_harabasz_score','davies_bouldin_score'],ascending=False)\n",
    "    display(df_)\n",
    "\n",
    "    predicted_labels = labels_kmeans[df_.index[0]]\n",
    "    predicted_centroids = centroids[df_.index[0]]\n",
    "    nb_cluster = df_.index[0]\n",
    "    return predicted_labels ,    nb_cluster,predicted_centroids \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d586a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_dict_dir(path_root = \"data\" , path_level_2 = \"test\" , current_path = None , level_0 = \"root\" , level_1 =[\"raw\" , \"meta\"] , level_2 = [\"txt\",\"img\",\"mp3\"]):\n",
    "    if current_path is None : \n",
    "        current_path = os.getcwd()\n",
    "   \n",
    "    data_path =  os.path.join(current_path,path_root)\n",
    "\n",
    "    lst_dir_info = level_2\n",
    "    dct_dir_info = {}\n",
    "    for e in lst_dir_info:\n",
    "        dct_dir_info.update({e:e})\n",
    "\n",
    "    for k in dct_dir_info.keys():\n",
    "        dct_dir_info[k] = os.path.join(path_level_2,dct_dir_info[k])\n",
    "\n",
    "    lst_dir_data =  level_1\n",
    "    dct_data_info = {}\n",
    "    for e in lst_dir_data:\n",
    "        dct_data_info.update({e:e})\n",
    "\n",
    "    _lst = [dct_data_info]+[dct_dir_info] #level_1 + level_2 \n",
    "\n",
    "    dct_total = {}\n",
    "    for i in range(len(_lst)): # 1 : level_1_value ; 2 : level_2_value\n",
    "        dct_total.update({i+1:_lst[i]})\n",
    "\n",
    "    for k0,v in dct_total.items():\n",
    "        for k in v.keys():\n",
    "            v[k] = os.path.join(data_path, v[k])\n",
    "            isExist = os.path.exists(v[k])\n",
    "            if not isExist : \n",
    "                os.makedirs(v[k])\n",
    "\n",
    "    dct_total.update({0:{level_0 :data_path}}) # 0: level_0_value\n",
    "    return dct_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_link_file( ids_links_str , root_dwn_dir ,filename = \"linkList.txt\") :\n",
    "    batch_link_dwn = os.path.join(root_dwn_dir,filename)\n",
    "    lst_links_str =getUrlsFromIds( ids_links_str) \n",
    "    with open(batch_link_dwn, 'w') as f:\n",
    "        for line in lst_links_str :\n",
    "            f.write(f\"{line}\\n\")\n",
    "    return batch_link_dwn , lst_links_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ytdlp_dwn( exec_ytdlp, batch_link_dwn , output_filename , isbatch = False ):  #, output_path ):\n",
    "    print(exec_ytdlp, batch_link_dwn , output_filename)\n",
    "    optionBatch = [\"-a\"] if isbatch else []\n",
    "    return subprocess.call([exec_ytdlp ]+optionBatch + [ batch_link_dwn    , \"--write-description\" ,\"--write-info-json\" , \"--skip-download\" , \"--youtube-skip-dash-manifest\" , \"-o\" ,output_filename    ],shell=True)  #,\"-P\" ,output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def index_representative_points(X,centroids ,  predicted_labels , n_cluster ):\n",
    "    ret = []\n",
    "    for k in range( n_cluster):\n",
    "        mask = (predicted_labels == k).nonzero()[0]\n",
    "        centroid = centroids[k]\n",
    "        i0 = mask[pairwise_distances_argmin(centroid[None, :], X[mask])[0]]\n",
    "        ret.append(i0)\n",
    "    return np.array(ret)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dfcc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def getSummaryTags(tags_list) : \n",
    "        words = word_tokenize(' '.join(tags_list))\n",
    "        nouns_and_verbs = []\n",
    "        lemmas = []\n",
    "        for n in words:\n",
    "                for token in nlp(n):\n",
    "                        if token.pos_ == 'NOUN' or token.pos_ == 'VERB':\n",
    "                                #print(f'{token.text:{8}} {token.pos_:{6}} {token.tag_:{6}} {token.dep_:{6}} {spacy.explain(token.pos_):{20}} {spacy.explain(token.tag_)}')\n",
    "                                if (token.lemma_ not in lemmas) :\n",
    "                                        lemmas.append(token.lemma_)\n",
    "                                        nouns_and_verbs.append(token.vector)\n",
    "\n",
    "        if(len(nouns_and_verbs) == 0):\n",
    "                return []\n",
    "        \n",
    "        predicted_labels , n_clusters ,centroids = find_best_cluster ( nouns_and_verbs ,2,10,1)\n",
    "        print(len(centroids) )\n",
    "        nouns_and_verbs = np.array(nouns_and_verbs)\n",
    "        most_rpz_idx = index_representative_points(nouns_and_verbs,centroids  ,  predicted_labels , n_clusters ) \n",
    "\n",
    "        summary_tags = []\n",
    "\n",
    "        for i in most_rpz_idx :\n",
    "            summary_tags.append(lemmas [i])\n",
    "\n",
    "        return summary_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7a994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getSubPartJson(content_file,prop_to_extract   ) :\n",
    "    meta_obj_json = dict.fromkeys(prop_to_extract)\n",
    "    for prop in prop_to_extract :\n",
    "        meta_obj_json[prop] = content_file[prop] if( prop in content_file) else []\n",
    "    return meta_obj_json\n",
    "\n",
    "\n",
    "def writeData(json_object ,filename,open_type =None) :\n",
    "    str_json_object = json.dumps(json_object, indent=4)\n",
    "    if(open_type == None):\n",
    "        open_type = 'a'\n",
    "    with open(filename, open_type) as outfile:\n",
    "        outfile.write(str_json_object)\n",
    "        \n",
    "    return filename \n",
    "\n",
    "def getDctDir(_id,dct_total ,pos_path,sub_dir):\n",
    "    if(pos_path in dct_total and sub_dir in dct_total[pos_path]):\n",
    "        meta_dwn_dir= dct_total[pos_path][sub_dir]\n",
    "        meta_info_dir = os.path.join(meta_dwn_dir,_id)\n",
    "        isExist = os.path.exists(meta_info_dir)\n",
    "        if not isExist:\n",
    "                os.makedirs(meta_info_dir)\n",
    "        return meta_info_dir\n",
    "\n",
    "\n",
    "def getMetaDir(_id,dct_total):\n",
    "    return  getDctDir( _id, dct_total , 1 ,'meta')\n",
    "\n",
    "def getRawDir(_id,dct_total):\n",
    "    return  getDctDir( _id , dct_total , 1 ,'raw')\n",
    "\n",
    "\n",
    "def getDfDescriptionFilename():\n",
    "    return \"fichier_test.description\"\n",
    "\n",
    "def matchArrowbaseYtParticipants( description):\n",
    "    return  re.findall(r\"\\W*(@[^\\s]+)\", description )\n",
    "\n",
    "\n",
    "def matchUrlParticipants (description ,reseau_video={\"https://www.twitch.tv/\":\"twitch\", \"https://www.youtube.com/\" :\"youtube\"}):\n",
    "    dct_find = dict()\n",
    "    for reseau in reseau_video.values():\n",
    "        dct_find.update({reseau:[]})\n",
    "        \n",
    "    for url_reseau ,reseau in reseau_video.items() :\n",
    "        url_reseau_escaped = str(url_reseau).replace(\"/[-[\\]{}()*+?.,\\\\^$|#\\s]/g\", \"\\\\$&\")\n",
    "        reg_ = url_reseau_escaped + r'[^\\s]+'\n",
    "        dct_find[reseau]+=re.findall(reg_, description )\n",
    "\n",
    "    return dct_find\n",
    "\n",
    "    \n",
    "\n",
    "def toUrlYtParticipants(exec_ytdlp  ,participants):\n",
    "    res=[]\n",
    "    for p in participants[1:] :\n",
    "        participant_url = \"https://www.youtube.com/\" + p\n",
    "        if(b_verifyUrlParticipant(exec_ytdlp  , participant_url)):\n",
    "            res.append(participant_url)\n",
    "    return res\n",
    "\n",
    "def getParticipants(exec_ytdlp  ,description):\n",
    "    dct_res = matchUrlParticipants (description)\n",
    " \n",
    "    find = matchArrowbaseYtParticipants(description)\n",
    "    dct_res[\"youtube\"]+=toUrlYtParticipants(exec_ytdlp  ,find)\n",
    "    return dct_res\n",
    "\n",
    "\n",
    "def retCodeCorrectRequestYtdlp():\n",
    "    return 0\n",
    "\n",
    "def b_verifyUrlParticipant(exec_ytdlp  ,url_participant):\n",
    "    return subprocess.call([exec_ytdlp , \"--playlist-items\"  , \"0\"  , \"--print\" , \"playlist:channel_url\"  , url_participant],shell=True)  == retCodeCorrectRequestYtdlp()\n",
    "    \n",
    "def getTestDir(_id,dct_total,sub_dir):\n",
    "    return  getDctDir( _id, dct_total , 2 ,sub_dir)\n",
    "\n",
    "def writeContextMetaData(exec_ytdlp  ,data,dct_total,open_type = None) :\n",
    "    _id =data['id']\n",
    "    meta_info_dir = getMetaDir(data['id'],dct_total)\n",
    "    meta_obj_json =getSubPartJson(data,[  \"id\",\"title\",\"uploader\",\"uploader_id\",\"uploader_url\",\"channel_id\",\"channel_url\",\"duration\",\"view_count\",\"age_limit\",\"webpage_url\",\"categories\",\"tags\",\"live_status\",\"comment_count\",\"like_count\",\"channel\",\"channel_follower_count\",\"upload_date\",\"availability\",\"webpage_url_basename\",\"webpage_url_domain\",\"display_id\",\"fulltitle\",\"duration_string\"])#,\"language_preference\"])\n",
    "    print(data)\n",
    "    meta_obj_json[\"summary_tags\" ] = getSummaryTags(data[\"tags\"])\n",
    "    \n",
    "    meta_raw_dir = getRawDir(_id,dct_total)\n",
    "    description_filename = os.path.join(meta_raw_dir,getDfDescriptionFilename() )\n",
    "    with open(description_filename, 'r') as outfile:\n",
    "        description = outfile.read()\n",
    "        meta_obj_json[\"participants\"] = getParticipants(exec_ytdlp ,description)\n",
    "    meta_info_filename = os.path.join(meta_info_dir,\"context_meta.json\")\n",
    "    writeData( meta_obj_json,meta_info_filename,open_type)\n",
    "\n",
    "def writeVideoMetaData(exec_ytdlp  , data,dct_total, nb_formats =10 ,open_type=None):\n",
    "    _id =data['id']\n",
    "    meta_info_dir = getMetaDir(_id,dct_total)\n",
    "    meta_obj_json =getSubPartJson(data,[\"duration\",\"chapters\",\"subtitles\",\"formats\"] )\n",
    "    meta_obj_json[\"formats\"] = meta_obj_json[\"formats\"][:nb_formats]\n",
    "    meta_info_filename = os.path.join(meta_info_dir,\"video_meta.json\")\n",
    "    writeData( meta_obj_json,meta_info_filename,open_type)\n",
    "    #getDescription(data['id'])\n",
    "    #writeData()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ccdac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video ( exec_ytdlp,dct_total,output_filename , lst_ID_links_str ,root_dwn_dir):\n",
    "   \n",
    "    batch_link_dwn ,lst_links_str = create_link_file (lst_ID_links_str,root_dwn_dir  )\n",
    "    errs_url = []\n",
    "    res_url = []\n",
    "    #Download des videos\n",
    "    for i,IDlink in enumerate(lst_ID_links_str) :\n",
    "        id_dir = getRawDir(IDlink,dct_total)\n",
    "        isExist = os.path.exists(id_dir)\n",
    "        if not isExist:\n",
    "                os.makedirs(id_dir)\n",
    "        filename = os.path.join(id_dir,output_filename )\n",
    "        err_subProcess =ytdlp_dwn(exec_ytdlp , lst_links_str[i] , filename ) #batch_link_dwn : fichier contenant les liens des videos à télécharger , output_filename : fichier de sortie contenant les metadonnées des videos téléchargées\n",
    "        if err_subProcess == -1 :\n",
    "            errs_url.append(lst_links_str[i])\n",
    "            print(\"Error download video\" + str(lst_links_str[i]))\n",
    "        else :\n",
    "            res_url.append(filename+\".info\"+\".json\")\n",
    "    return  res_url, errs_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabbc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_directories ( dct_total,exec_ytdlp,output_filename , lst_ID_links_str ,root_dwn_dir , isId = True ):\n",
    "\n",
    "            \n",
    "    outputs_full_names ,_ = download_video ( exec_ytdlp,dct_total,output_filename , lst_ID_links_str ,root_dwn_dir)\n",
    "\n",
    "    for output_full_name in outputs_full_names :\n",
    "        f = open(output_full_name)\n",
    "        \n",
    "        data = json.load(f)\n",
    "\n",
    "\n",
    "        writeContextMetaData(exec_ytdlp,data,dct_total,open_type=\"w\") \n",
    "        writeVideoMetaData(exec_ytdlp,data,dct_total,open_type=\"w\")\n",
    "\n",
    "\n",
    "        f.close()\n",
    "  \n",
    "    return outputs_full_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ddb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStartMs():\n",
    "     return 'tStartMs'\n",
    "def getDurationMs():\n",
    "     return 'dDurationMs'\n",
    "\n",
    "def getSubtitleFromListTimes( jsonSubt_events ,list_times) :\n",
    "    k=0\n",
    "    res = []\n",
    "    sub_times = []\n",
    "    b= True \n",
    "    for  time in list_times :\n",
    "        lst = []\n",
    "\n",
    "        while( b and jsonSubt_events[k][getStartMs()] + jsonSubt_events[k][getDurationMs()] < time[0] ) :\n",
    "            k+=1\n",
    "            if( k == len(jsonSubt_events) ) :\n",
    "                b= False\n",
    "        if(b):\n",
    "            lst.append(jsonSubt_events[k]['segs'][0]['utf8'])\n",
    "            sub_times.append([jsonSubt_events[k][getStartMs()] ,jsonSubt_events[k][getDurationMs()]  ] )\n",
    "            while( b and  jsonSubt_events[k][getStartMs()] + jsonSubt_events[k][getDurationMs()] < time[1] ) :\n",
    "                    k+=1\n",
    "                    lst.append(jsonSubt_events[k]['segs'][0]['utf8'])\n",
    "                    sub_times.append([jsonSubt_events[k][getStartMs()] ,jsonSubt_events[k][getDurationMs()]  ] )\n",
    "                    if( k == len(jsonSubt_events) ) :\n",
    "                        b= False\n",
    "\n",
    "        res.append(lst)\n",
    "\n",
    "        if(not(b)):\n",
    "            return res ,sub_times\n",
    "    return res ,sub_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30689fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def milliTimeto_second( time ):#attends un temps en millisecondes\n",
    "    return time/1000\n",
    "\n",
    "\n",
    "def rawDuration_toSeconds(duration):\n",
    "    print(duration)\n",
    "    return [ milliTimeto_second(e) for e in duration ]\n",
    "\n",
    "\n",
    "\n",
    "def rawDurations_toSeconds(durations):\n",
    "    return [ rawDuration_toSeconds(e ) for e  in durations ] \n",
    "\n",
    "\n",
    "def getSecondIntervalFromTimesMilli(interval_times_sort_mili) : \n",
    "    second_interval_times =[]\n",
    "    for i in range(len(interval_times_sort_mili )) :\n",
    "        second_interval_times.append( rawDurations_toSeconds(interval_times_sort_mili[i]))\n",
    "    return second_interval_times\n",
    "\n",
    "\n",
    "def secondTimeto_secminhours( time ):#attends un temps en  secondes\n",
    "\n",
    "        seconds ,minutes= math.modf(time/60)\n",
    "        heures = 0\n",
    "        print(seconds, minutes)\n",
    "        if minutes > 60  :\n",
    "                minutes , heures= math.modf(minutes/60)\n",
    "                minutes = round(minutes * 60 ,2 )\n",
    "        else :\n",
    "            seconds = round(seconds *0.6 ,2 )\n",
    "        return [heures,minutes,seconds]\n",
    "\n",
    "def milliTimeto_secminhours( time ):\n",
    "    return secondTimeto_secminhours( milliTimeto_second( time) )\n",
    "     \n",
    "def milliTimeto_min( time ):\n",
    "    return milliTimeto_second( time)/60\n",
    "\n",
    "def secmin_to_str( times ):\n",
    "    str_res = \"\"\n",
    "    i=0\n",
    "    print(times)\n",
    "    for  time in times:\n",
    "        if i == (len(times)-1):\n",
    "            print(\"time \" + str(time))\n",
    "            stre = (str(time).split(\".\"))[1][:2]\n",
    "        else:\n",
    "            stre = (str(time).split(\".\"))[0] \n",
    "        print(\"stre \" + stre)\n",
    "        if( len(stre) <2 ):\n",
    "            stre = \"0\" + stre\n",
    "\n",
    "        str_res += \":\" + stre \n",
    "        i+=1\n",
    "    str_time = [\"hours\",\"minutes\",\"seconds\"]\n",
    "    tail = \"\"\n",
    "    for k in range(i,len(str_time)):\n",
    "            tail  += \"00:\"\n",
    "    \n",
    "    return tail+str_res[1:]\n",
    "            \n",
    "\n",
    "def secondTimeto_str( time ):\n",
    "    return secmin_to_str( secondTimeto_secminhours( time ) )\n",
    "def milliTimeto_str( time ):\n",
    "    return secmin_to_str( milliTimeto_secminhours( time ) )\n",
    "\n",
    "def toSectionTimeCode( lst_times ):\n",
    "    res = []\n",
    "    for e in lst_times:\n",
    "        res.append(\"-\".join(e))\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2905202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeCategories_retInterval(n_clusters, predicted_kmeans, heatMarker_flt,max=90000):\n",
    "        print(\"MERGE CATE \")\n",
    "        print( n_clusters , predicted_kmeans , heatMarker_flt)\n",
    "\n",
    "        arr_interval = [[] for i in range(n_clusters)]\n",
    "        \n",
    "        for i,e in enumerate(predicted_kmeans):\n",
    "            arr_interval[e].append([heatMarker_flt [i][0],heatMarker_flt [i][1]])\n",
    "        arr_interval.sort(key=lambda x: x[0])\n",
    "\n",
    "        weights = []\n",
    "        intervals = []\n",
    "        for e in arr_interval:\n",
    "            for i in range(len(e)):\n",
    "                elm = e[i][0]\n",
    "                if(i == 0):\n",
    "                    beg = [elm,elm]\n",
    "                    weight = e[i][1]\n",
    "                else:\n",
    "                    if(elm < beg[0]):\n",
    "                        beg[0]=elm\n",
    "\n",
    "                    if elm > beg[1]:\n",
    "                        if(elm - beg[0] > max):\n",
    "                            intervals.append([beg[0],beg[1]] )\n",
    "                            weights.append(weight)\n",
    "                            beg[0] =  beg[1] =elm\n",
    "                            weight = e[i][1]\n",
    "                        else:\n",
    "                            print(\"icic\")\n",
    "                            beg[1] = elm\n",
    "                            weight += e[i][1]\n",
    "            intervals.append([beg[0],beg[1]] )\n",
    "            weights.append(weight)\n",
    "              \n",
    "                \n",
    "        '''\n",
    "            beg = arr_interval[e]\n",
    "            if(elm < beg[0]):\n",
    "                    beg[0]=elm\n",
    "\n",
    "            if elm > beg[1]:\n",
    "                if(elm - beg[0] > max):\n",
    "                        arr_interval[e].append([beg[0],beg[1]] )\n",
    "                        weights[e].append(weights[e])\n",
    "                        beg[0] =  beg[1] =elm\n",
    "                        weights[e] = 0\n",
    "                else:\n",
    "                        beg[1] = elm\n",
    "                        weights[e] +=heatMarker_flt [i][1]\n",
    "        '''\n",
    "                        \n",
    "                \n",
    "                \n",
    "            \n",
    "        return  intervals , weights\n",
    "\n",
    "def getIdxNotSignifiantWeight(arr_interval,weights):\n",
    " \n",
    "        idx_filter = []\n",
    "\n",
    "        for i in range(len(weights)) :\n",
    "            lgth = (arr_interval[i][1] -arr_interval[i][0]) * pow(10,-4)\n",
    "            weights[i] = weights[i] / lgth if lgth != 0 else weights[i]\n",
    "            if(weights[i] < 0.5 ):\n",
    "                idx_filter.append(i) \n",
    "        return idx_filter\n",
    "\n",
    "def filterAndSortArr( arr_interval,weights,idx_filter=[]):\n",
    "        arr_weights = np.array([weights[i] for i in range(len(weights)) if i not in idx_filter])\n",
    "        arr_e = np.array([arr_interval[i] for i in range(len(arr_interval)) if i not in idx_filter])\n",
    "\n",
    "\n",
    "        idx_sort = [i[0] for i in sorted(enumerate(arr_e ), key=lambda x:x[1][0])]\n",
    "        arr_e_sort = np.array(arr_e)[idx_sort]\n",
    "        weights_sort = np.array(arr_weights)[idx_sort]\n",
    "\n",
    "        return arr_e_sort,weights_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergeCategories_retInterval(2,[1,1,0,0,0,0,0], [[5713490, 0.6071078100432646], [5715490, 1], [23455380, 0.5440194935904227], [24358410, 0.6187778955466057], [24360410, 0.5770295807850397], [27063900, 0.5238282322906579], [29168870, 0.529939425996983]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da96384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getFirstNFormat ( jsonSubt_formats , needs_str,  num_format = 2 ) : #suppose classe par fileSize croissant\n",
    "    lst_format = []\n",
    "    for jf in jsonSubt_formats:\n",
    "         print(jf[\"format\"])\n",
    "         if(all([x in  jf[\"format\"] for x in needs_str]) ):\n",
    "            num_format-=1\n",
    "            lst_format.append(jf)\n",
    "            if(num_format == 0 ):\n",
    "                return lst_format\n",
    "\n",
    "def getFirstNMp3Format ( jsonSubt_formats , num_format = 1 ) : #suppose classe par fileSize croissant\n",
    "    return getFirstNFormat ( jsonSubt_formats , [\"audio only\"] , num_format )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e054d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRegexCommandToDlSection(section_timecode_todl,only_audio=True):\n",
    "    lst_dwnl_section_cmd = []\n",
    "    for section_t_code in section_timecode_todl :\n",
    "            lst_dwnl_section_cmd+= [\"--download-sections\" ,\"*\"+section_t_code ]+ [\"--extract-audio\" ] if only_audio else []\n",
    "    return lst_dwnl_section_cmd\n",
    "\n",
    "def dlSectionFromTimes (times_centi ,exec_ytdlp , output_path,  ytLink ,only_audio=False ,filename = None ):\n",
    "    if filename is None :\n",
    "        filename = \"audio_section\"\n",
    "    print(filename , output_path)\n",
    "    section_timecode_todl_1 = [list(map( secondTimeto_str , e )) for e in times_centi ]\n",
    "    print(section_timecode_todl_1)\n",
    "    section_timecode_todl_2 = toSectionTimeCode(section_timecode_todl_1)\n",
    "    lst_dwnl_section_cmd = getRegexCommandToDlSection(section_timecode_todl_2,only_audio)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    output_file = os.path.join(output_path , filename)\n",
    "    print(output_file,ytLink,exec_ytdlp)\n",
    "\n",
    "    return subprocess.call([exec_ytdlp  ] +lst_dwnl_section_cmd + [\"--downloader\",  \"aria2c\" ,ytLink ,\"-o\",  output_file+\"_\"+'%(autonumber)s'   ],shell=True) \n",
    "\n",
    "      \n",
    "def writeMp3FromTimes(jsonSubt_formats , _id , times_centi , exec_ytdlp, output_path,  filename = None ):\n",
    "    formatMp3 = getFirstNMp3Format ( jsonSubt_formats )\n",
    "    ytLink = getUrlsFromIds([_id])[0]\n",
    "    return dlSectionFromTimes (times_centi ,exec_ytdlp , output_path,  ytLink ,only_audio=True ,filename =filename   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735dea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def getTimesIntervals(lst_ID_links_str,exec_ytdlp):\n",
    "\n",
    "    heatMarkers_datas =  getvideosInfos(lst_ID_links_str)\n",
    "    heatMarkers_wh=getHeatMarkersDatasVideos(heatMarkers_datas)\n",
    "\n",
    "    intervals_times_sort = []\n",
    "    heatmarks_weights_sort = []\n",
    "    max_duration = 1.5 \n",
    "    for i,heatMarker_wh in enumerate(heatMarkers_wh):\n",
    "        if( len(heatMarker_wh) == 0 ):\n",
    "            continue\n",
    "        len_video=getLenVideo(heatMarker_wh)\n",
    "\n",
    "        \n",
    "        while( True  ) :\n",
    "            heatMarker_flt ,  m  =filterData(heatMarker_wh)\n",
    "            print(\"heatMarker_flt : \" + str(heatMarker_flt))#(temps , poids)\n",
    "\n",
    "            predicted_kmeans , n_clusters ,_ = find_best_cluster ( heatMarker_flt  ,2,8 ,1)\n",
    "\n",
    "            interval_time ,heatmark_weight = mergeCategories_retInterval(n_clusters, predicted_kmeans, heatMarker_flt)\n",
    "\n",
    "            if(milliTimeto_min(m) <= max_duration):\n",
    "                break\n",
    "            else :\n",
    "                tme=interval_time.copy()\n",
    "                for z in range(len(tme)) :\n",
    "                    tme[z][1]=tme[z][1]+m \n",
    "\n",
    "                tme=rawDurations_toSeconds(interval_time)\n",
    "\n",
    "                dlSectionFromTimes (tme ,exec_ytdlp , \"D:\\\\Master\\\\S2\\\\GestionProjet\\\\tmp\",  getUrlsFromIds([lst_ID_links_str[i]])[0] ,only_audio=True, filename = \"audio_cluster\" )\n",
    "                break\n",
    "\n",
    "           \n",
    "        \n",
    "        idx_filter = getIdxNotSignifiantWeight(interval_time,heatmark_weight) if(milliTimeto_min(m) < max_duration  ) else []\n",
    "\n",
    "        \n",
    "\n",
    "        interval_time_sort , heatmark_weight_sort = filterAndSortArr(  interval_time ,heatmark_weight ,idx_filter)\n",
    "\n",
    "\n",
    "        intervals_times_sort.append(interval_time_sort)\n",
    "        heatmarks_weights_sort.append(heatmark_weight_sort)\n",
    "    print(\"intervals_times_sort : \" + str(intervals_times_sort))\n",
    "    print(\"heatmarks_weights_sort : \" + str(heatmarks_weights_sort))\n",
    "\n",
    "    return intervals_times_sort,heatmarks_weights_sort\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ead07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEventSubtitle(url) :\n",
    "    xer = requests.get(url)\n",
    "    json_obj = json.loads(xer.text)\n",
    "    return json_obj[\"events\"]\n",
    "\n",
    "def getFirstSubtitle(video_meta_filename ,ext = [\"json3\",\"srv2\",\"srv3\"]):\n",
    "    #oepn video meta file load json and extract \"subtitles\" fields\n",
    "    f = open(video_meta_filename)\n",
    "    data = json.load(f )\n",
    "    ext_found = [\"\"for i in range(len(ext))]\n",
    "    url_base = data[\"subtitles\"][\"en\"]\n",
    "    i=0\n",
    "    url= url_base[i]\n",
    "    while (bool(url) and url[\"ext\"] != ext[0]):\n",
    "        try:\n",
    "            idx= ext.index(url[\"ext\"])\n",
    "            ext_found[idx]=url[\"ext\"]\n",
    "        except ValueError:\n",
    "            pass\n",
    "        i+=1\n",
    "        url =  url_base[i] if i < len(url_base) else None\n",
    "    if(bool(url)):\n",
    "        i=0\n",
    "        return  getEventSubtitle(url[\"url\"]) ,ext[i]\n",
    "    else:\n",
    "        for i in range(len(ext)):\n",
    "            if(ext_found[i] != \"\"):\n",
    "                return  ext_found[i],ext[i] \n",
    "        return None,None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotwords(text):\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] # 1\n",
    "    doc = nlp(text.lower()) # 2\n",
    "    for token in doc:\n",
    "        # 3\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        # 4\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "                \n",
    "    return result # 5\n",
    "\n",
    "def getPosImage ( time , atm_time ,cur_dur ,  u , nb_col ):\n",
    "        #print(time , atm_time , u , nb_col )\n",
    "        diff_time = time - ( atm_time  -cur_dur) \n",
    "        num = (diff_time * u)/cur_dur\n",
    "        num_row = math.floor(num / nb_col)\n",
    "        num_col = math.floor(num % nb_col)\n",
    "        return [num_row,num_col]\n",
    "\n",
    "\n",
    "def getFirstNImageFormat ( jsonSubt_formats , num_format = 3 ) : #suppose classe par fileSize croissant\n",
    "    return getFirstNFormat ( jsonSubt_formats , [\"(storyboard)\"] , num_format ) \n",
    "\n",
    "def getUrlImageTilesFromTimes( format  ,list_times  ) :\n",
    "    k=0\n",
    "    res = []\n",
    "    b= True \n",
    "    atm_time = 0\n",
    "    fragment = format[\"fragments\"]\n",
    "    nb_row = format[\"rows\"]\n",
    "    nb_col = format[\"columns\"]\n",
    "    u = nb_row * nb_col \n",
    "\n",
    "    for  z, time in enumerate(list_times) :\n",
    "        lst = []\n",
    "\n",
    "        while( b and atm_time  < time[0] ) :\n",
    "            atm_time += fragment[k][\"duration\"]\n",
    "            k+=1\n",
    "            if( k == len(fragment) ) :\n",
    "                b= False \n",
    "        if(b):\n",
    "            pair_pos = getPosImage (time[0] ,  atm_time ,fragment[k][\"duration\"] , u , nb_col)\n",
    "            lst.append( [fragment[k][\"url\"]] +[z] +  [pair_pos] )\n",
    "\n",
    "            while( b and   atm_time  < time[1] ) :\n",
    "                    k+=1\n",
    "                 \n",
    "                    \n",
    "                    if( k == len(fragment) ) :\n",
    "                        b= False\n",
    "                    else:\n",
    "                        atm_time += fragment[k][\"duration\"]\n",
    "                        pair_pos = getPosImage (time[1] ,  atm_time,fragment[k][\"duration\"] , u , nb_col)\n",
    "                        lst.append( [fragment[k][\"url\"]] +[z] +[pair_pos] )\n",
    "                    \n",
    "\n",
    "        res+=lst\n",
    "\n",
    "        if(not(b)):\n",
    "            return res\n",
    "    return res \n",
    "\n",
    "\n",
    "def writeImageFromTiles(lst_tiles ,times ,  img_out_dir , width , height ):\n",
    "     pos_url = 0 \n",
    "     category_time =  1 \n",
    "     pos_tiles = 2\n",
    "     print(img_out_dir)\n",
    "     idxs = [0 for i in range(len(times))]\n",
    "     for i, tiles in enumerate(lst_tiles) :\n",
    "        image_url = tiles[pos_url]\n",
    "        tiles_pos = tiles[pos_tiles]\n",
    "        time = times[tiles[category_time]]\n",
    "        idxs[tiles[category_time]]+=1\n",
    "        response = requests.get(image_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        crop_rectangle = (tiles_pos[1] * width, tiles_pos[0] * height, (tiles_pos[1] + 1) * width, (tiles_pos[0] + 1) * height)\n",
    "        cropped_im = img.crop(crop_rectangle)\n",
    "\n",
    "        filename = '_'.join(map(str,time+[idxs[tiles[category_time]]]) )+'.png'\n",
    "        cropped_im.save(os.path.join(img_out_dir ,filename))\n",
    "        #imgplot = plt.imshow(img)\n",
    "        #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def getFormats():\n",
    "    return 'formats'\n",
    "\n",
    "\n",
    "def writeImageFromTimes(jsonSubt_formats ,times_centi ,  img_out_dir  ):\n",
    "    formats = getFirstNImageFormat ( jsonSubt_formats  )#recupere le dernier format : celui qui contient le plus d'images non groupé : niveau de grain le plus faible\n",
    "    format = formats[len(formats)-1] \n",
    "\n",
    "    lst_urlsAndPos_image = getUrlImageTilesFromTimes( format  , times_centi ) #extrait du format les urls des images et les positions des images dans les tiles\n",
    "\n",
    "    height = jsonSubt_formats[2][\"height\"]\n",
    "    width = jsonSubt_formats[2][\"width\"]\n",
    "\n",
    "    return writeImageFromTiles(lst_urlsAndPos_image ,times_centi  ,  img_out_dir , width , height )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a7e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_path = os.getcwd()\n",
    "\n",
    "output_path = os.path.join(current_path,\"test\")\n",
    "\n",
    "dct_total = init_dict_dir() \n",
    "print(dct_total)\n",
    "\n",
    "\n",
    "#Path vers le git de yt-dlp\n",
    "path_ytdlp = os.path.join(current_path, \"yt-dlp\")\n",
    "exec_ytdlp = os.path.join(path_ytdlp, \"yt-dlp\")\n",
    "\n",
    "#input filename info\n",
    "root_dwn_dir= dct_total[0]['root']\n",
    "\n",
    "#Output filename info \n",
    "raw_dwn_dir = dct_total[1]['raw']\n",
    "output_filename = \"fichier_test\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lst_ID_links_str = [\"AOKBuz9yJJ8\"]\n",
    "outputs = init_directories ( dct_total,exec_ytdlp,output_filename , lst_ID_links_str ,root_dwn_dir )\n",
    "print(lst_ID_links_str)\n",
    "\n",
    "\n",
    "intervals_times_sort,heatmarks_weights_sort = getTimesIntervals(lst_ID_links_str,exec_ytdlp )\n",
    "\n",
    "print(intervals_times_sort,heatmarks_weights_sort)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(outputs)\n",
    "\n",
    "\n",
    "json_obj= {getStartMs(): 0 , getDurationMs(): 0 , \"tags\" : []}\n",
    "for i  in range(len(intervals_times_sort )):\n",
    "    _id = lst_ID_links_str[i]\n",
    "    video_meta_filename = outputs[i]\n",
    "    interval_time_sort = intervals_times_sort[i]\n",
    "    subtitle,_ = getFirstSubtitle(video_meta_filename)\n",
    "    subtitles_times ,sub_times = getSubtitleFromListTimes( subtitle ,interval_time_sort )\n",
    "    k = 0\n",
    "    json_to_write = []\n",
    "    for z  in range(len(subtitles_times)) :\n",
    "        subtitles_time= subtitles_times[z]\n",
    "        for x in range(len(subtitles_time)):\n",
    "            e = subtitles_time[x]\n",
    "            t = sub_times[k]\n",
    "            doc =  get_hotwords(e)\n",
    "            json_obj_tmp = json_obj.copy()\n",
    "            json_obj_tmp[getStartMs()] = t[0] \n",
    "            json_obj_tmp[getDurationMs()] = t[1] \n",
    "            json_obj_tmp[\"tags\"] = doc\n",
    "            json_to_write.append(json_obj_tmp)\n",
    "            k+=1\n",
    "    path_dir_txt = getTestDir(_id,dct_total,\"txt\") \n",
    "    filename_subtitle = os.path.join(path_dir_txt , \"subtitles\"+\".json\" )      \n",
    "    with open(filename_subtitle, 'w') as outfile:\n",
    "        json.dump(json_to_write, outfile)\n",
    "        \n",
    "    \n",
    "centi_interval_times = rawDuration_toSeconds(intervals_times_sort )\n",
    "\n",
    "for i  in range(len(intervals_times_sort  )):\n",
    "    _id = lst_ID_links_str[i]\n",
    "    meta_dir = getMetaDir(_id,dct_total)\n",
    "    filename_video = os.path.join(meta_dir , \"video_meta\" +\".json\")\n",
    "    print(filename_video)\n",
    "    f2 = open(filename_video, \"r\")\n",
    "    json_meta_vid =  json.load(f2 )\n",
    "    f2.close()\n",
    "    jsonSubt_formats = json_meta_vid[getFormats()]\n",
    "    format = getFirstNImageFormat ( jsonSubt_formats  )\n",
    "    print(format[len(format)-1])\n",
    "\n",
    "    interval_time_sort = centi_interval_times[i]\n",
    "    \n",
    "    writeImageFromTimes(jsonSubt_formats ,  interval_time_sort ,getTestDir(_id,dct_total,'img')  )\n",
    "    \n",
    "    writeMp3FromTimes(jsonSubt_formats , _id , interval_time_sort  , exec_ytdlp, getTestDir(_id,dct_total,'mp3')   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wav2Vec2ClassificationHead(nn.Module):\n",
    "    \"\"\"Head for wav2vec classification task.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.dropout = nn.Dropout(config.final_dropout)\n",
    "        self.out_proj = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = features\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = torch.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d34fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wav2Vec2ForSpeechClassification(Wav2Vec2PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.pooling_mode = config.pooling_mode\n",
    "        self.config = config\n",
    "\n",
    "        self.wav2vec2 = Wav2Vec2Model(config)\n",
    "        self.classifier = Wav2Vec2ClassificationHead(config)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def freeze_feature_extractor(self):\n",
    "        self.wav2vec2.feature_extractor._freeze_parameters()\n",
    "\n",
    "    def merged_strategy(\n",
    "            self,\n",
    "            hidden_states,\n",
    "            mode=\"mean\"\n",
    "    ):\n",
    "        if mode == \"mean\":\n",
    "            outputs = torch.mean(hidden_states, dim=1)\n",
    "        elif mode == \"sum\":\n",
    "            outputs = torch.sum(hidden_states, dim=1)\n",
    "        elif mode == \"max\":\n",
    "            outputs = torch.max(hidden_states, dim=1)[0]\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_values,\n",
    "            attention_mask=None,\n",
    "            output_attentions=None,\n",
    "            output_hidden_states=None,\n",
    "            return_dict=None,\n",
    "            labels=None,\n",
    "    ):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        outputs = self.wav2vec2(\n",
    "            input_values,\n",
    "            attention_mask=attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        hidden_states = outputs[0]\n",
    "        hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n",
    "        logits = self.classifier(hidden_states)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SpeechClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d927c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name_or_path = \"harshit345/xlsr-wav2vec-speech-emotion-recognition\"\n",
    "config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name_or_path)\n",
    "sampling_rate = feature_extractor.sampling_rate\n",
    "model = Wav2Vec2ForSpeechClassification.from_pretrained(model_name_or_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e598b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(path, sampling_rate):\n",
    "    speech_array, _sampling_rate = torchaudio.load(path)\n",
    "    resampler = torchaudio.transforms.Resample(_sampling_rate)\n",
    "    speech = resampler(speech_array).squeeze().numpy()\n",
    "    return speech\n",
    "def predict(path, sampling_rate):\n",
    "    speech = speech_file_to_array_fn(path, sampling_rate)\n",
    "    inputs = feature_extractor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {key: inputs[key].to(device) for key in inputs}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    scores = F.softmax(logits, dim=1).detach().cpu().numpy()[0]\n",
    "    outputs = [{\"Emotion\": config.id2label[i], \"Score\": f\"{round(score * 100, 3):.1f}%\"} for i, score in enumerate(scores)]\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sr = 16000\n",
    " \n",
    "# if you change code below, it will download the dataset again \n",
    "db = audb.load(\n",
    "    'emodb',\n",
    "    version='1.1.1',\n",
    "    format='wav',\n",
    "    mixdown=True,\n",
    "    sampling_rate=sr,\n",
    "    full_path=False,\n",
    "    verbose=True,\n",
    ")\n",
    " \n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.emobase,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58023a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SpeechClassifierOutput(ModelOutput):\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb947582",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = 'C:/Users/julien/audb/emodb/1.1.1/fe182b91/wav/10a07Wb.wav'   \n",
    "outputs = predict(path_2, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650c4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs)\n",
    "speech_array, _sampling_rate = torchaudio.load(path_2 )\n",
    "print(speech_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c977ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lll= \"D:/Master/S2/GestionProjet/test_video_.wav\"\n",
    "speech_array, _sampling_rate = torchaudio.load(lll)\n",
    "print(speech_array.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b233068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fs, data = wavfile.read(lll)            # reading the file\n",
    "\n",
    "wavfile.write(\"D:/Master/S2/GestionProjet/audio_section_channel_1.wav\", fs, data[:, 0])   # saving first column which corresponds to channel 1\n",
    "wavfile.write(\"D:/Master/S2/GestionProjet/audio_section_channel_2.wav\", fs, data[:, 1])   # saving second column which corresponds to channel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a85874",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputs_2 = predict(\"D:/Master/S2/GestionProjet/audio_section_channel_2.wav\", sampling_rate)\n",
    "print(outputs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fccdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lll=\"D:/Master/S2/GestionProjet/billy-scream.wav\"\n",
    "fs, data = wavfile.read(lll)            # reading the file\n",
    "\n",
    "wavfile.write(\"D:/Master/S2/GestionProjet/billy-scream_channel_1.wav\", fs, data[:, 0])   # saving first column which corresponds to channel 1\n",
    "wavfile.write(\"D:/Master/S2/GestionProjet/billy-scream_channel_2.wav\", fs, data[:, 1])   # saving second column which corresponds to channel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "classifier = foreign_class(source=\"speechbrain/emotion-recognition-wav2vec2-IEMOCAP\", pymodule_file=\"custom_interface.py\", classname=\"CustomEncoderWav2vec2Classifier\")\n",
    "out_prob, score, index, text_lab = classifier.classify_file(\"D:/Master/S2/GestionProjet/billy-scream_channel_1.wav\")\n",
    "print(text_lab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
